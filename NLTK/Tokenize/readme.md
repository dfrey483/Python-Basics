Python NLTK Tokenize [9 exercises with solution]
What is Tokenize?

Tokenization is the process of demarcating and possibly classifying sections of a string of input characters. The resulting tokens are then passed on to some other form of processing. The process can be considered a sub-task of parsing input.

1. Write a Python NLTK program to split the text sentence/paragraph into a list of words. 
Click me to see the sample solution

2. Write a Python NLTK program to tokenize sentences in languages other than English. 
Click me to see the sample solution

3. Write a Python NLTK program to create a list of words from a given string. 
Click me to see the sample solution

4. Write a Python NLTK program to split all punctuation into separate tokens. 
Click me to see the sample solution

5. Write a Python NLTK program to tokenize words, sentence wise. 
Click me to see the sample solution

6. Write a Python NLTK program to tokenize a twitter text. 
Click me to see the sample solution

7. Write a Python NLTK program to remove Twitter username handles from a given twitter text. 
Click me to see the sample solution

8. Write a Python NLTK program that will read a given text through each line and look for sentences. Print each sentence and divide two sentences with "==============". 
Click me to see the sample solution

9. Write a Python NLTK program to find parenthesized expressions in a given string and divides the string into a sequence of substrings. 
Click me to see the sample solution
